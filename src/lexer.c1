#use <string>
//#use "regex.c0"

struct l_token_t {
    /*
        - A: assignment operator
        - I: identifier
        - K: keyword
        - L: literal
        - S: separator
        - O: operator
        - W: whitespace
    */
    char type;
    string str;

    // token position
    int row;
    int col;
};
typedef struct l_token_t l_token_t;

string l_regex_or(string a, string b) {
    return format("(%s)|(%s)", a, b);
}

/*
    Tokenizes the given string and populates the tokens list. Returns the number
    of tokens.
*/
vec_t *l_tokenize(string code) {
    int src_ptr = 0;
    vec_t *tokens = v_create_vector();

    // pieces
    string R_NUM = "0|[1-9][0-9]*|0[xX][0-9a-fA-F]+";
    string R_ESC = format(
        "%s|%s", 
        "\\\\n|\\\\t|\\\\v|\\\\b|\\\\r", 
        "\\\\f|\\\\a|\\\\|\\\\\'|\\\\\""
    );
    string R_NCHAR = "[ !#-~]";
    string R_LCHAR = "[!-=?-~]";
    string R_SCHAR = l_regex_or(R_ESC, R_NCHAR);
    string R_CCHAR = l_regex_or(R_SCHAR, "\\\\0");
    string R_STRLIT = format("\"(%s)*\"", R_SCHAR);
    string R_CHRLIT = format("'%s'", R_CCHAR);
    string R_LIT = format("(%s)|(%s)|(%s)", R_NUM, R_CHRLIT, R_STRLIT);
    string R_OP_FST = "!|~|-|\\*|\\.|->|/|%|\\+|<<|>>|<|<=|>=|>|==|!=|&";
    string R_OP_SND = "^|\\||&&|\\|\\||\\?|:|--|\\+\\+";
    string R_OP = format("%s|%s", R_OP_FST, R_OP_SND);

    // actual keywords
    re_dfa_t *R_IDENTIFIER = re_parse_regex("[a-zA-Z_][a-zA-Z0-9_]*");
    re_dfa_t *R_SEP = re_parse_regex("[()[\\]{},;]");
    re_dfa_t *R_ASN_OP = re_parse_regex(
        "=|\\+=|-=|\\*=|/=|%=|<<=|>>=|&=|^=|\\|="
    );
    re_dfa_t *R_WHITE = re_parse_regex("(\\s+)|(//[^\n]*\n)|(/\\*.*\\*/)");
    re_dfa_t *R_LITERAL = re_parse_regex(R_LIT);
    re_dfa_t *R_OPERATOR = re_parse_regex(R_OP);

    // yes ik ugly
    int n_token_types = 6;
    re_dfa_t *[] regexs = alloc_array(re_dfa_t *, n_token_types);
    regexs[0] = R_IDENTIFIER;
    regexs[1] = R_SEP;
    regexs[2] = R_ASN_OP;
    regexs[3] = R_WHITE;
    regexs[4] = R_LITERAL;
    regexs[5] = R_OPERATOR;

    char[] token_types = alloc_array(char, n_token_types);
    token_types[0] = 'I';
    token_types[1] = 'S';
    token_types[2] = 'A';
    token_types[3] = 'W';
    token_types[4] = 'L';
    token_types[5] = 'O';

    // tokenizer position init
    int row = 1;
    int col = 0;

    while (src_ptr != string_length(code)) {
        int token_size = 0;
        char token_type = '\0';

        for (int i = 0; i < n_token_types && token_size == 0; i++) {
            token_size = re_run_dfa(
                regexs[i], code, src_ptr, token_types[i] == 'W'
            );
            if (token_size != 0) {
                token_type = token_types[i];
            }
        }

        // lexer failed
        if (token_size == 0) {
            string details = format("(Line %d, Col %d)", row, col);
            printf(
                "Lexer error: invalid token at character position %d %s\n",
                src_ptr, details
            );
            return NULL;
        }

        string matched = string_sub(code, src_ptr, src_ptr + token_size);

        // change to keyword/literal for special identifiers
        if (token_type == 'I') {
            if (u_is_keyword(matched)) token_type = 'K';
            else if (u_is_literal(matched)) token_type = 'L';
        }

        if (token_type != 'W') {
            l_token_t *token = alloc(l_token_t);
            token->type = token_type;
            token->str = matched;
            token->row = row;
            token->col = col;

            v_append(tokens, (void *) token);
        }

        // increment misc position trackers
        src_ptr += token_size;
        for (int i = 0; i < string_length(matched); i++) {
            if (string_charat(matched, i) == '\n') {
                row++;
                col = 0;
            } else {
                col++;
            }
        }
    }

    return tokens;
}
