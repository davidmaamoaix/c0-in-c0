#use <string>

struct l_token_t {
    /*
        - A: assignment operator
        - I: identifier
        - K: keyword
        - L: literal
        - S: separator
        - O: operator
        - W: whitespace
    */
    char type;
    string str;
    fr_pos_t *pos;
};
typedef struct l_token_t l_token_t;

string l_regex_or(string a, string b) {
    return format("(%s)|(%s)", a, b);
}

/*
    Tokenizes the given string and populates the `tokens` field of the file
    representation.
*/
e_error_t *l_tokenize(fr_file_t *repr) {
    int src_ptr = 0;
    vec_t *tokens = v_create_vector();
    repr->libs = v_create_vector();

    // pieces
    string R_NUM = "0|[1-9][0-9]*|0[xX][0-9a-fA-F]+";
    string R_ESC = format(
        "%s|%s", 
        "\\\\n|\\\\t|\\\\v|\\\\b|\\\\r", 
        "\\\\f|\\\\a|\\\\|\\\\\'|\\\\\""
    );
    string R_NCHAR = "[ !#-~]";
    string R_LCHAR = "[!-=?-~]";
    string R_SCHAR = l_regex_or(R_ESC, R_NCHAR);
    string R_CCHAR = l_regex_or(R_SCHAR, "\\\\0");
    string R_STRLIT = format("\"(%s)*\"", R_SCHAR);
    string R_CHRLIT = format("'(%s)'", R_CCHAR);
    string R_LIT = format("(%s)|(%s)|(%s)", R_NUM, R_CHRLIT, R_STRLIT);
    string R_OP_FST = "!|~|-|\\*|\\.|->|/|%|\\+|<<|>>|<|<=|>=|>|!=|&";
    string R_OP_SND = "^|\\||&&|\\|\\||\\?|:|--|\\+\\+";
    string R_OP = format("%s|%s", R_OP_FST, R_OP_SND);
    string R_USELIT = "#use[ \f\n\r\t\v]*<[!-=?-~]*>[ \f\n\r\t\v]*\n";

    // actual keywords
    re_dfa_t *R_IDENTIFIER = re_parse_regex("[a-zA-Z_][a-zA-Z0-9_]*");
    re_dfa_t *R_SEP = re_parse_regex("[()[\\]{},;]");
    // treat `==` as an ASN_OP to avoid conflict with `=`
    re_dfa_t *R_ASN_OP = re_parse_regex(
        "==|=|\\+=|-=|\\*=|/=|%=|<<=|>>=|&=|^=|\\|="
    );
    re_dfa_t *R_WHITE = re_parse_regex("(\\s+)|(//[^\n]*\n)|(/\\*.*\\*/)");
    re_dfa_t *R_LITERAL = re_parse_regex(R_LIT);
    re_dfa_t *R_OPERATOR = re_parse_regex(R_OP);
    re_dfa_t *R_USE = re_parse_regex(R_USELIT);

    // yes ik ugly
    int n_token_types = 7;
    re_dfa_t *[] regexs = alloc_array(re_dfa_t *, n_token_types);
    regexs[0] = R_WHITE;
    regexs[1] = R_ASN_OP;
    regexs[2] = R_SEP;
    regexs[3] = R_OPERATOR;
    regexs[4] = R_LITERAL;
    regexs[5] = R_IDENTIFIER;
    regexs[6] = R_USE;

    char[] token_types = alloc_array(char, n_token_types);
    token_types[0] = 'W';
    token_types[1] = 'A';
    token_types[2] = 'S';
    token_types[3] = 'O';
    token_types[4] = 'L';
    token_types[5] = 'I';
    token_types[6] = 'U';

    // tokenizer position init
    int row = 1;
    int col = 1;
    string code = repr->prog;

    while (src_ptr != string_length(code)) {
        int token_size = 0;
        char token_type = '\0';

        for (int i = 0; i < n_token_types && token_size == 0; i++) {
            token_size = re_run_dfa(
                regexs[i], code, src_ptr, token_types[i] == 'W'
            );
            if (token_size != 0) {
                token_type = token_types[i];
            }
        }

        // lexer failed
        if (token_size == 0) {
            fr_pos_t *invalid_pos = fr_create_pos(row, col, row, col);
            return e_create_error("invalid token", invalid_pos);
        }

        string matched = string_sub(code, src_ptr, src_ptr + token_size);

        // change to keyword/literal for special identifiers
        if (token_type == 'I') {
            if (u_is_keyword(matched)) token_type = 'K';
            else if (u_is_literal(matched)) token_type = 'L';
        }

        if (token_type == 'A' && string_equal(matched, "==")) {
            token_type = 'O';
        }

        if (token_type == 'U') {
            // assert that `use` contains '<' and '>'
            int str_pc = 0;
            while (string_charat(matched, str_pc) != '<') str_pc++;

            int begin_index = str_pc + 1;
            while (string_charat(matched, str_pc) != '>') str_pc++;

            string lib_str = string_sub(matched, begin_index, str_pc);
            v_append_string(repr->libs, lib_str);
        }

        if (token_type != 'W' && token_type != 'U') {
            l_token_t *token = alloc(l_token_t);
            token->type = token_type;
            token->str = matched;
            
            token->pos = fr_create_pos(row, col, row, col + token_size);

            v_append(tokens, (void *) token);
        }

        // increment misc position trackers
        src_ptr += token_size;
        for (int i = 0; i < string_length(matched); i++) {
            if (string_charat(matched, i) == '\n') {
                row++;
                col = 1;
            } else {
                col++;
            }
        }
    }

    repr->tokens = tokens;
    return NULL;
}
